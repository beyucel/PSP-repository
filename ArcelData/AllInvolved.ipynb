{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.io import loadmat\n",
    "import numpy as np\n",
    "from sklearn.linear_model import BayesianRidge, LinearRegression\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import ConstantKernel, RBF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = loadmat('DataforFit.mat')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=data['TrainProperty02']\n",
    "X=data['averagePcScores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yucel\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BayesianRidge(alpha_1=1e-06, alpha_2=1e-06, compute_score=True, copy_X=True,\n",
       "       fit_intercept=True, lambda_1=1e-06, lambda_2=1e-06, n_iter=300,\n",
       "       normalize=False, tol=0.001, verbose=False)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = BayesianRidge(compute_score=True)\n",
    "clf.fit(X, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def err(x1,x2):\n",
    "    error=abs(x2-x1)/x2\n",
    "#   print (error)\n",
    "    return error\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1478.34100418, -2290.52133851,   996.54814514,  2319.75615264,\n",
       "       -1330.09701347,  -474.29326028])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat=clf.predict(X).reshape(16,1)\n",
    "\n",
    "ols = LinearRegression()\n",
    "ols.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024359576747075586"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err(ols.predict(X),y).sum()/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02721972])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(err(y_hat,y)/16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16, 1)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import LeaveOneOut\n",
    "loo = LeaveOneOut()\n",
    "loo.get_n_splits(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yucel\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:578: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 1  2  3  4  5  6  7  8  9 10 11 12 13 14 15] TEST: [0]\n",
      "[[-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]] [[586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[641.7575]]\n",
      "TRAIN: [ 0  2  3  4  5  6  7  8  9 10 11 12 13 14 15] TEST: [1]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]] [[641.7575]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[586.542]]\n",
      "TRAIN: [ 0  1  3  4  5  6  7  8  9 10 11 12 13 14 15] TEST: [2]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]] [[641.7575]\n",
      " [586.542 ]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[602.3725]]\n",
      "TRAIN: [ 0  1  2  4  5  6  7  8  9 10 11 12 13 14 15] TEST: [3]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[536.0675]]\n",
      "TRAIN: [ 0  1  2  3  5  6  7  8  9 10 11 12 13 14 15] TEST: [4]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[511.0605]]\n",
      "TRAIN: [ 0  1  2  3  4  6  7  8  9 10 11 12 13 14 15] TEST: [5]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[766.784]]\n",
      "TRAIN: [ 0  1  2  3  4  5  7  8  9 10 11 12 13 14 15] TEST: [6]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[700.0695]]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  8  9 10 11 12 13 14 15] TEST: [7]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[684.925]]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  9 10 11 12 13 14 15] TEST: [8]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[649.955]]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8 10 11 12 13 14 15] TEST: [9]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[648.257]]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 11 12 13 14 15] TEST: [10]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[601.227]]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 12 13 14 15] TEST: [11]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[594.326]]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 13 14 15] TEST: [12]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [574.538 ]\n",
      " [862.9575]\n",
      " [676.478 ]] [[583.0125]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 14 15] TEST: [13]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [862.9575]\n",
      " [676.478 ]] [[574.538]]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 15] TEST: [14]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [676.478 ]] [[862.9575]]\n",
      "TRAIN: [ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14] TEST: [15]\n",
      "[[-0.01206686 -0.02311451 -0.00917529  0.00302907  0.00281945 -0.00110773]\n",
      " [-0.04321941 -0.0122951   0.00091181 -0.00329273  0.00594966 -0.00025994]\n",
      " [ 0.00672726 -0.00259795 -0.00779799 -0.00194821  0.0032816  -0.00170879]\n",
      " [-0.03176064  0.03313103  0.00754749  0.0045861  -0.00270223  0.00033475]\n",
      " [-0.04680588  0.02704906  0.01464697  0.00594077  0.00362692 -0.0006239 ]\n",
      " [ 0.00709518 -0.03669919 -0.00533507  0.00840916  0.00047621 -0.00070186]\n",
      " [ 0.03438806 -0.00550495 -0.00792708  0.00581713 -0.00118548  0.0050296 ]\n",
      " [ 0.03434151  0.00042198 -0.00678504  0.00546724 -0.00376569  0.0011789 ]\n",
      " [ 0.07201958  0.01400266  0.00228164 -0.01763053  0.00433997 -0.0007964 ]\n",
      " [-0.01077828 -0.00363166 -0.00537903 -0.00124408 -0.00104492 -0.00144516]\n",
      " [-0.0580591  -0.03488848  0.00431069 -0.01351934 -0.00684538  0.00218816]\n",
      " [ 0.01223359  0.0286289  -0.00496884 -0.00310027 -0.00250456 -0.00196983]\n",
      " [ 0.0075376   0.03337434 -0.00363945 -0.00122466 -0.00321444  0.00124981]\n",
      " [-0.02499669  0.01809744  0.00091871  0.00322273  0.00018074  0.00092537]\n",
      " [ 0.06441782 -0.03068797  0.02369518  0.00715729 -0.0009735  -0.00118888]] [[-0.01107373 -0.00528559 -0.00330471 -0.00166964  0.00156166 -0.0011041 ]] [[641.7575]\n",
      " [586.542 ]\n",
      " [602.3725]\n",
      " [536.0675]\n",
      " [511.0605]\n",
      " [766.784 ]\n",
      " [700.0695]\n",
      " [684.925 ]\n",
      " [649.955 ]\n",
      " [648.257 ]\n",
      " [601.227 ]\n",
      " [594.326 ]\n",
      " [583.0125]\n",
      " [574.538 ]\n",
      " [862.9575]] [[676.478]]\n"
     ]
    }
   ],
   "source": [
    "LOOCVerr=[]\n",
    "LOOCVerrOLS=[]\n",
    "LOOCVerrGPR=[]\n",
    "\n",
    "\n",
    "for train_index, test_index in loo.split(X):\n",
    "    print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "    X_train, X_test = X[train_index], X[test_index]\n",
    "    y_train, y_test = y[train_index], y[test_index]\n",
    "    print(X_train, X_test, y_train, y_test)\n",
    "    clf = BayesianRidge(compute_score=True)\n",
    "    clf.fit(X_train[:,0:3], y_train)\n",
    "    ols = LinearRegression()\n",
    "    ols.fit(X_train[:,0:3], y_train)\n",
    "    y_hat=clf.predict(X_test[:,0:3]).reshape(1,1)\n",
    "    y_hat2=ols.predict(X_test[:,0:3]).reshape(1,1)\n",
    "    LOOCVerr.append(err(y_hat,y_test))\n",
    "    LOOCVerrOLS.append(err(y_hat2,y_test))\n",
    "    noise=0.5\n",
    "    rbf = ConstantKernel(1.0) * RBF(length_scale=5.0)\n",
    "    gpr = GaussianProcessRegressor(kernel=rbf, alpha=noise**2)\n",
    "    gpr.fit(X_train, y_train)\n",
    "    yhat_3, cov_s = gpr.predict(X, return_cov=True)\n",
    "    LOOCVerrGPR.append(err(yhat_3,y_test))\n",
    "    \n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05538180147001151"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(LOOCVerr)/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.059503841280351015"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(LOOCVerrOLS)/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import GPy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " C:\\Users\\yucel\\Anaconda3\\lib\\site-packages\\GPy\\core\\gp.py:87: UserWarning:Your kernel has a different input dimension 1 then the given X dimension 6. Be very sure this is what you want and you have not forgotten to set the right input dimenion in your kernel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style type=\"text/css\">\n",
       ".pd{\n",
       "    font-family: \"Courier New\", Courier, monospace !important;\n",
       "    width: 100%;\n",
       "    padding: 3px;\n",
       "}\n",
       "</style>\n",
       "\n",
       "<p class=pd>\n",
       "<b>Model</b>: GP regression<br>\n",
       "<b>Objective</b>: 126251.01135177577<br>\n",
       "<b>Number of Parameters</b>: 3<br>\n",
       "<b>Number of Optimization Parameters</b>: 2<br>\n",
       "<b>Updates</b>: True<br>\n",
       "</p>\n",
       "<style type=\"text/css\">\n",
       ".tg  {font-family:\"Courier New\", Courier, monospace !important;padding:2px 3px;word-break:normal;border-collapse:collapse;border-spacing:0;border-color:#DCDCDC;margin:0px auto;width:100%;}\n",
       ".tg td{font-family:\"Courier New\", Courier, monospace !important;font-weight:bold;color:#444;background-color:#F7FDFA;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg th{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;color:#fff;background-color:#26ADE4;border-style:solid;border-width:1px;overflow:hidden;word-break:normal;border-color:#DCDCDC;}\n",
       ".tg .tg-left{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:left;}\n",
       ".tg .tg-center{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:center;}\n",
       ".tg .tg-right{font-family:\"Courier New\", Courier, monospace !important;font-weight:normal;text-align:right;}\n",
       "</style>\n",
       "<table class=\"tg\"><tr><th><b>  GP_regression.         </b></th><th><b>  value</b></th><th><b>constraints</b></th><th><b>priors</b></th></tr>\n",
       "<tr><td class=tg-left>  rbf.variance           </td><td class=tg-right>232.886</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  rbf.lengthscale        </td><td class=tg-right> 0.1216</td><td class=tg-center>    +ve    </td><td class=tg-center>      </td></tr>\n",
       "<tr><td class=tg-left>  Gaussian_noise.variance</td><td class=tg-right>   0.25</td><td class=tg-center> +ve fixed </td><td class=tg-center>      </td></tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<GPy.models.gp_regression.GPRegression at 0x1e0c8cf99e8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rbf = GPy.kern.RBF(input_dim=1, variance=232.886, lengthscale=0.1216)\n",
    "gpr = GPy.models.GPRegression(X, y, rbf)\n",
    "\n",
    "# Fix the noise variance to known value \n",
    "gpr.Gaussian_noise.variance = noise**2\n",
    "gpr.Gaussian_noise.variance.fix()\n",
    "\n",
    "# Run optimization\n",
    "#gpr.optimize();\n",
    "\n",
    "# Display optimized parameter values\n",
    "display(gpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtain optimized kernel parameters\n",
    "l = gpr.rbf.lengthscale.values[0]\n",
    "sigma_f = np.sqrt(gpr.rbf.variance.values[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "yyyy=gpr.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[641.7575],\n",
       "       [586.542 ],\n",
       "       [602.3725],\n",
       "       [536.0675],\n",
       "       [511.0605],\n",
       "       [766.784 ],\n",
       "       [700.0695],\n",
       "       [684.925 ],\n",
       "       [649.955 ],\n",
       "       [648.257 ],\n",
       "       [601.227 ],\n",
       "       [594.326 ],\n",
       "       [583.0125],\n",
       "       [574.538 ],\n",
       "       [862.9575],\n",
       "       [676.478 ]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.080388977602395"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err(yyyy,y)[0,:,0].sum()/16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 16, 1)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(yyyy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "Testdata = loadmat('Testdatainfo.mat')\n",
    "y_test=Testdata['RealVals']\n",
    "X_test=Testdata['TestdataAverageScores']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hatBLR=clf.predict(X_test[:,0:3]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.07552176721311434"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err(y_hatBLR,y_test).sum()/3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hatOLS=ols.predict(X_test[:,0:3]).reshape(-1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05413469119438014"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "err(y_hatOLS,y_test).sum()/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[704.70010503],\n",
       "       [669.27850774],\n",
       "       [836.31330083],\n",
       "       [590.65602065]])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hatOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[0.04238877]]),\n",
       " array([[0.03774544]]),\n",
       " array([[0.07934113]]),\n",
       " array([[0.03322749]]),\n",
       " array([[0.04482264]]),\n",
       " array([[0.06484841]]),\n",
       " array([[0.0131202]]),\n",
       " array([[0.00874821]]),\n",
       " array([[0.15284626]]),\n",
       " array([[0.0407673]]),\n",
       " array([[0.10832575]]),\n",
       " array([[0.02413082]]),\n",
       " array([[0.03636845]]),\n",
       " array([[0.02888789]]),\n",
       " array([[0.16254132]]),\n",
       " array([[0.07395138]])]"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LOOCVerrOLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import openpyxl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "xfile = openpyxl.load_workbook('ErrorValues.xlsx')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheet = xfile.get_sheet_by_name('CLD-LR')\n",
    "for i in range(1,17):\n",
    "    c1 = sheet.cell(row = i+1, column = 1) \n",
    "    c1.value =(float(LOOCVerrOLS[i-1]))\n",
    "errors=err(y_hatOLS,y_test)\n",
    "for i in range(1,5):\n",
    "    c1 = sheet.cell(row = i+1, column = 7)\n",
    "    c1.value =(float(errors[i-1]))\n",
    "xfile.save('ErrorValues.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05413469119438014"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.sum(errors)/4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For BLR\n",
    "sheet = xfile.get_sheet_by_name('CLD-BLR ')\n",
    "for i in range(1,17):\n",
    "    c1 = sheet.cell(row = i+1, column = 1) \n",
    "    c1.value =(float(LOOCVerr[i-1]))\n",
    "errors=err(y_hatBLR,y_test)\n",
    "for i in range(1,5):\n",
    "    c1 = sheet.cell(row = i+1, column = 7)\n",
    "    c1.value =(float(errors[i-1]))\n",
    "xfile.save('ErrorValues.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(15, 6)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.01206686, -0.02311451, -0.00917529],\n",
       "       [-0.04321941, -0.0122951 ,  0.00091181],\n",
       "       [ 0.00672726, -0.00259795, -0.00779799],\n",
       "       [-0.03176064,  0.03313103,  0.00754749],\n",
       "       [-0.04680588,  0.02704906,  0.01464697],\n",
       "       [ 0.00709518, -0.03669919, -0.00533507],\n",
       "       [ 0.03438806, -0.00550495, -0.00792708],\n",
       "       [ 0.03434151,  0.00042198, -0.00678504],\n",
       "       [ 0.07201958,  0.01400266,  0.00228164],\n",
       "       [-0.01077828, -0.00363166, -0.00537903],\n",
       "       [-0.0580591 , -0.03488848,  0.00431069],\n",
       "       [ 0.01223359,  0.0286289 , -0.00496884],\n",
       "       [ 0.0075376 ,  0.03337434, -0.00363945],\n",
       "       [-0.02499669,  0.01809744,  0.00091871],\n",
       "       [ 0.06441782, -0.03068797,  0.02369518]])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[:,0:3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
